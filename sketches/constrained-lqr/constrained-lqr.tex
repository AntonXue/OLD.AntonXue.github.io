\documentclass[12pt]{article}

% Packages
\usepackage[margin=5em]{geometry} % 1 cm = 2.84528 em
\usepackage[backend=bibtex]{biblatex}
\bibliography{sources}
% \nocite{*}

\usepackage{lipsum}

% Paragraphs
\setlength{\parindent}{0em}
\setlength{\parskip}{1em}

% Includes
\input{axlib.tex}

% Author
\title{Constrained Linear Quadratic Regular Optimization}
\author{Anton Xue}
\date{\today}
\date{}

% Document
\begin{document}
\maketitle

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\section{Introduction}
We look at constrained linear quadratic regulator (LQR) optimization.

\section{Background}
Relevant background on linear systems, LQR, and matrix magic.

\subsection{Linear Systems and the Linear Quadratic Regulator}
Linear system dynamics
\begin{align*}
  x_{t + 1} = A x_t + B u_t,
    \qquad (x_t)_{t = 0}^{\infty} \in \mbb{R}^n,
    \quad (u_t)_{t = 0}^{\infty} \in \mbb{R}^p,
\end{align*}
Finite horizion linear quadratic regular (LQR) cost function
\begin{align*}
  J = \sum_{t = 0}^{T} x_t ^\top Q x_t + u_t ^\top R u_t,
    \qquad
    Q \succeq 0, \quad R \succ 0,
\end{align*}
which is finite when the system dynamics \((x_t, u_t)\)
tends towards the origin.
Infinite-horizon LQR average-cost function
\begin{align*}
  J = \limsup_{T \to \infty} \frac{1}{T} \sum_{t = 0}^{T - 1}
        x_t ^\top Q x_t + u_t ^\top R u_t,
    \qquad
    Q \succeq 0, \quad R \succ 0,
\end{align*}
which allows for systems whose stability is not necessarily at the origin.
Both versions of LQR admit an optimal feedback control sequence
that is linear, \ie, \(u = Kt\),
with respect to the algebraic Riccati equation in \(P\) where
\begin{align*}
  P = Q + A^\top P A - A^\top P B (R + B^\top P B)^{-1} B^\top P A,
    \qquad K = -(R + B^\top P B)^{-1} B^\top P A
\end{align*}
where the solution for \(P \succ 0\), if it exists, is unique.

\subsection{Affine Systems}
Given the affine system
\begin{align*}
  x_{t + 1} = A x_t + B u_t + c
\end{align*}
we can reformulate it as a linear system
\begin{align}
  z_{t + 1}
    = \begin{bmatrix} x_{t + 1} \\ 1 \end{bmatrix}
    = \begin{bmatrix} A & c \\ 0 & 1 \end{bmatrix}
      \begin{bmatrix} x_t \\ 1 \end{bmatrix}
      + \begin{bmatrix} B \\ 0 \end{bmatrix}
        u_t
    = \tilde{A} z_t + \tilde{B} u_t
    \label{eqn:affine-system}
\end{align}

\subsection{Completing the Square}
For the matrix case with variable in \(x\)
from Wikipedia~\cite{wiki2020square},
\begin{align}
  x^\top Q x + p^\top x + r
    = (x - h)^\top Q (x - h) + k,
    \qquad h = - \frac{1}{2} Q^{-1} p,
    \qquad k = r - \frac{1}{4} p^\top Q^{-1} p
    \label{eqn:matrix-square}
\end{align}
where \(Q\) is assumed to be invertible.


%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\section{Some Results with Affine Constraints}

\begin{theorem}
  \label{thm:affine-lqr}
  An infinite horizon average-cost LQR problem with
  quadratic-plus-affine terms
  \begin{align*}
    \text{minimize}
      &\quad \limsup_{T \to \infty} \frac{1}{T}
        \sum_{t = 0}^{T - 1}
          x_t ^\top Q x_t + q^\top x_t + q_0
          + u_t ^\top R u_t + r^\top u_t + r_0 \\
    \text{subject to}
      &\quad x_{t + 1} = A x_t + B u_t, \enskip \text{for all \(t\)}
  \end{align*}
  admits an equivalent infinite horizon average-cost LQR problem
  without affine terms.
\end{theorem}
\begin{proof}
  Applying \eqref{eqn:matrix-square} we can write the objective as
  \begin{align*}
    \limsup_{T \to \infty}
    \frac{1}{T} \sum_{t = 0}^{T - 1}
      (x_t - h) ^\top Q (x_t - h)
      + (u_t - l)^\top R (u_t - l) + k,
  \end{align*}
  with coefficients
  \begin{align*}
    h = - \frac{1}{2} Q^{-1} q,
    \qquad l = - \frac{1}{2} R^{-1} r,
    \qquad k = q_0 + r_0 - \frac{1}{4} \parens{q^\top Q q + r^\top R r}
  \end{align*}
  Observe that \(k\) is constant with respect to the variables
  \((x_t, u_t)\) and the objective is equivalently
  \begin{align*}
    k + \limsup_{T \to \infty} \frac{1}{T} \sum_{t = 0}^{T - 1}
      (x_t - h)^\top Q (x_t - h) + (u_t - l)^\top R (u_t - l).
  \end{align*}
  Define the change-of-variables
  \(\tilde{x}_t = x_t - h\) and \(\tilde{u}_t = u_t - l\) for all \(t\),
  which induces the affine system
  \begin{align*}
    \tilde{x}_{t + 1} = A \tilde{x}_t + B \tilde{u}_t + (A h + B l - h)
  \end{align*}
  and after the appropriate change of variables to recover a linear system
  as in \eqref{eqn:affine-system},
  \begin{align*}
    z_{t + 1}
      = \begin{bmatrix} A & (Ah + Bl - h) \\ 0 & 1 \end{bmatrix}
        \begin{bmatrix} \tilde{x}_t \\ 1 \end{bmatrix}
        + \begin{bmatrix} B \\ 0 \end{bmatrix}
          \tilde{u}_t
      = \tilde{A} z_t + \tilde{B} \tilde{u}_t.
  \end{align*}
  For this, the reduced problem is then
  \begin{align*}
    \text{minimize}
      &\quad k + \limsup_{T \to \infty} \frac{1}{T} \sum_{t = 0}^{T - 1}
        z_t ^\top \begin{bmatrix} Q & 0 \\ 0 & 0 \end{bmatrix} z_t
        + \tilde{u}_t ^\top R \tilde{u}_t \\
    \text{subject to}
      &\quad z_{t + 1}
        = \begin{bmatrix} A & (Ah + Bl - h) \\ 0 & 1 \end{bmatrix}
          z_t
          + \begin{bmatrix} B \\ 0 \end{bmatrix}
          \tilde{u}_t, \enskip \text{for all \(t\)}
  \end{align*}
  with variables in \((z_t)_{t = 0}^{\infty}\)
  and \((u_t)_{t = 0}^{\infty}\).
  Barring the \(k\) offset in the objective,
  this is now equivalent to an infinite horizion average-cost
  LQR problem with no affine terms.
\end{proof}

Because quadratic-plus-affine terms can be eliminated to yield
a problem with purely quadratic cost,
Theorem~\ref{thm:affine-lqr} implies that
quadratic systems also have an optimal feedback control sequence
that is linear for the equivalent system with
trajectory in \((z_t, \tilde{u}_t)_{t = 0}^{\infty}\).
But since \((z_t, \tilde{u}_t)\) are linear transformations of
the original trajectory \((x_t, u_t)\),
the optimal feedback policy for the original dynamics is also linear.

\begin{theorem}
  The infinite-horizon average-cost LQR problem with affine constraints
  \begin{align*}
    \text{minimize}
      &\quad \limsup_{T \to \infty} \frac{1}{T} \sum_{t = 0}^{T - 1}
        x_t ^\top Q x_t + u_t ^\top R u_t \\
    \text{subject to}
      &\quad x_{t + 1} = A x_t + B u_t, \enskip \text{for all \(t\)} \\
      &\quad C x_t = d, \enskip \text{for all \(t\)}
  \end{align*}
  where \(C\) is fat and full rank,
  admits an optimal feedback control policy that is linear if:
  \begin{itemize}
    \item There exists \(\hat{u}\) such that
      \(\hat{x} = A \hat{x} + B \hat{u}\), where
      \(\hat{x} = C^\dagger d\).

    \item \(\ran AN \subseteq \ran B\),
      where \(\ran N = \ker C\).
  \end{itemize}
\end{theorem}
\begin{proof}
  Supposing the assumptions, we can write our system dynamics as
  \begin{align*}
    \hat{x} + N x_{t + 1}
      = A \parens{\hat{x} + N x_t} + B \parens{\hat{u} + v_t}
  \end{align*}
  where we treat \(N\) as a projection matrix onto \(\ker C\).
  However this is not quite in a standard linear systems form.
  Further factor the system matrices into
  \(A = A_1 + A_2\) and \(B = B_1 + B_2\) such that
  \begin{align*}
    \ran A_1 \subseteq \ran B_1 \subseteq \ker C^\perp,
      \qquad \ran A_2 \subseteq \ran B_2 \subseteq \ker C,
  \end{align*}
  Let \(y_t = N x_t\); the goal of such factorization is to ensure that
  \begin{align*}
    A_1 y_t + B_1 v_t = 0 \in \ker C^\perp,
      \qquad
      A_2 y_t + B_2 v_t \in \ker C
  \end{align*}
  In effect, the \((A_1, B_1)\) sub-system needs to eliminate
  action in \(\ker C^\perp\):
  for which appropriate \(v_t\) can be found given \(y_t\)
  due to the (linear) \(\ran AN \subseteq \ran B\) assumption.
  while \((A_2, B_2)\) is parameterized to lie purely in \(\ker C\).
  Thus, we need only care about the \((A_2, B_2)\) sub-system,
  for which results can be linearly translated back to the
  original \((A, B)\) system.
  Define the following for compactness,
  \begin{align*}
    J(y_t, v_t)
      &= \begin{bmatrix} \hat{x} \\ y_t \end{bmatrix}^\top
        \begin{bmatrix} Q & 0 \\ 0 & Q \end{bmatrix}
        \begin{bmatrix} \hat{x} \\ y_t \end{bmatrix}
        + \begin{bmatrix} 0 \\ 2 Q \hat{x} \end{bmatrix}^\top
          \begin{bmatrix} \hat{x} \\ y_t \end{bmatrix}
        + \begin{bmatrix} \hat{u} \\ v_t \end{bmatrix}^\top
          \begin{bmatrix} R & 0 \\ 0 & R \end{bmatrix}
          \begin{bmatrix} \hat{u} \\ v_t \end{bmatrix}
        + \begin{bmatrix} 0 \\ 2 R \hat{x} \end{bmatrix}^\top
          \begin{bmatrix} \hat{u} \\ v_t \end{bmatrix} \\
  \end{align*}
  and noting that
  \begin{align*}
    x_t ^\top Q x_t + u_t ^\top R u_t
      = \parens{\hat{x} + y_t}^\top Q \parens{\hat{x} + y_t}
        + \parens{\hat{u} + v_t}^\top R \parens{\hat{u} + v_t}
      = J(y_t, v_t)
  \end{align*}
  makes it so that the optimizatoin problem can be written as
  \begin{align*}
    \text{minimize}
      &\quad
        \limsup_{T \to \infty} \frac{1}{T} \sum_{t = 0}^{T - 1}
          J(y_t, v_t) \\
    \text{subject to}
      &\quad y_{t + 1} = A_2 y_t + B_2 v_t
  \end{align*}
  with variables in \((y_t)_{t = 0}^{\infty}\) and \((v_t)_{t = 0}^{\infty}\).
  Since \(J\) is a quadratic-plus-affine decomposition of the
  state and control costs,
  we know that this infinite-horizon average-cost LQR problem.
  As noted earlier,
  this system is derived from linear transformations on our original
  system \((A, B)\), and so an optimal controller linear for \((A_2, B_2)\)
  also implies linearity for \((A, B)\).

\end{proof}



\printbibliography

\end{document}

