
\section{Background}

We now introduce and give a quick overview of some of the background
material relevant.


\subsection{Regular Languages and Finite Automata}

Language recognition is a fundamental problem in theoretical computer science.
Given an alphabet of unique symbols \(\Sigma\),
let \(\Sigma^\star\) denote the set of all possible finite strings over
the alphabet \(\Sigma\).
For some set of strings that we call a language \(L \subseteq \Sigma^\star\)
and string \(w \in \Sigma^\star\),
we then ask if \(w \in L\).
This is the language recognition problem.

A number of problems in theoretical computer science can be formulated
in terms of language recognition.
Does this string belong to the set (language) of valid email addresses?
Does this stirng belong to the set (language) of valid
computer programs written in my favorite programming language?
Does this string belong to the set (language) of solutions
to an instance of the boolean satisfiability problem?

Here we are primarily concerned with recognizing regular languages.
These are the languages that can be described by regular expressions,
and see widespread application in text parsing.
Equivalently stated, regular languages are precisely the set of languages
recognized by the set of non-deterministic finite automata (NFA),
which we aim to study here.

Formally, a NFA is a tuple
\(\parens{\Sigma, Q, \delta, S, F}\)
that represents a finite state transition machine
which accepts or rejects strings.
Here \(\Sigma\) is the alphabet,
\(Q\) is the set of states,
\(\type{\Delta}{\Sigma \times Q}{\powset{Q}}\) is the transition function,
\(S \subseteq Q\) is the set of initial states,
and \(F \subseteq Q\) is the set of final states.

A NFA accepts a string if there exists a sequence of transition
starting from some \(q_s \in S\)
that ends in \(q_f \in F\).
As the transition function maps to a set of possible states that may
be arbitrarily chosen,
only the existence of a transition sequence is necessary,
hence the term non-deterministic.

\begin{example}[NFA]
  The NFA below operators over the binary alphabet
  \(\Sigma = \braces{0, 1}\).

  \begin{center}
  \begin{tikzpicture}
    [->,
     >=stealth',
     shorten >=1pt,
     auto,
     node distance=2cm,
     semithick,
     state/.style={circle, draw, minimum size=1cm} 
    ]

    \node[state, initial] (q0) at (0, 2) {\(q_0\)};
    \node[state] (q1) at (4, 4) {\(q_1\)};
    \node[state, accepting] (q2) at (4, 0) {\(q_2\)};

    \draw (q0) edge [above] node{\(0\)} (q1);
    \draw (q1) edge [left] node{\(1\)} (q2);
    \draw (q0) edge [below] node{\(0\)} (q2);
  \end{tikzpicture}
  \end{center}

  In order for a NFA to accept a string, there must exist a sequence
  of transitions (which may be non-unique).
  This particular NFA accepts precisely two strings:
  \begin{enumerate}
    \item[(1)]
      The string \(0\) through the transition sequence \(q_0 q_2\).

    \item[(2)]
      The string \(01\) through the transition sequence \(q_0 q_1 q_2\).
  \end{enumerate}
  Note that from state \(q_0\) there are two out-edges that
  are both weighted with \(0\).
  This is what differentiates an NFA from a
  deterministic finite automata (DFA).
  In an NFA, out-edges from the same vertex may have shared labels,
  but in a DFA all out-edges from the same vertex may not share labels.

\end{example}



%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\if false
A regular language is a language that can be recongnized by a regular
expression.
Such languages play a central role in theoretical comptuer science
and formal language theory due to their ability to simply describe a
large class of strings.
We now formalize these terms.

Given a finite set of unique symbols \(\Sigma\) called the alphabet,
write the set of all finite strings constructed over this alphabet
as \(\Sigma^\star\).
A string is nothing more than a finite sequences of symbols from an alphabet.
Let \(\varepsilon\) denote the empty string which contains no symbols.

\begin{example}
  Consider an alphabet \(\Sigma = \braces{a, \alpha, b, \beta, \div}\),
  examples of strings (finite sequences) that can be constructed
  with this alphabet include
  \begin{align*}
    ab\beta\beta\alpha
      \qquad \qquad
    \div\div a \beta
      \qquad \qquad
    a a a a a a a
      \qquad \qquad
    \varepsilon
      \qquad \qquad
  \end{align*}
\end{example}

A language \(L\) is nothing more than a set of strings.
In other words, \(L \subseteq \Sigma^\star\).
We are now ready to introduce the concept of a regular language.
Formally, regular languages are a family of languages inductively
defined as follows:

\begin{enumerate}
  \item[(1)]
    The empty set \(\emptyset\) and the empty string language
    \(\braces{\varepsilon}\) are regular languages.

  \item[(2)]
    For each symbol \(a \in \Sigma\),
    the singleton language \(\braces{a}\) is a regular language.

  \item[(3)]
    If \(A\) and \(B\) are regular languages,
    then so is their union \(A \cup B\),
    their concatenation \(A \cdot B\), and their Kleene star \(A^\star\),
    defined as:
    \begin{align*}
      A \cup B
        &= \braces{w \st w \in A \cup B} \\
      A \cdot B
        &= \braces{w_a \cdot w_b \st w_a \in A, w_b \in B} \\
      A^\star
        &= \braces{w^k \st k \in \N, w \in A}
    \end{align*}
    Where \(w^k\) is the k-fold concatenation of a string to itself,
    and \(w_a \cdot w_b\) is the concatenaiton of strings
    \(w_a\) and \(w_b\).
    Sometimes we write \(w_a w_b\) for concatenation when context is clear.

  \item[(4)]
    No other languages are regular.
\end{enumerate}

As alluded to earlier,
regular languages are precisely languages
that are recognized by the set of regular expressions.
For a regular expression \(R\) to recognize a language \(L\) means that
the regular expression \(R\) can describe every string in \(L\).
We now make this more concrete.
Given an alphabet \(\Sigma\),
a regular expression is defined inductively as follows


\begin{enumerate}
  \item[(1)]
    The empty regular expression denotes the empty language \(\emptyset\).
    The empty string \(\varepsilon\) describes the
    language containing only the empty string \(\braces{\varepsilon}\).
    For each symbol \(a \in \Sigma\), 
    the regular expression of just \(a\) matches the language
    \(\braces{a}\).

  \item[(2)]
    Given regular expressions \(R\) and \(S\),
    the following operations are regular expressions
    \begin{enumerate}
      \item[(a)]
        Concatenation \(RS\) is a regular expression that denotes
        the 

      \item[(b)]
      
      \item[(c)]
    \end{enumerate}

  \item[(3)]
\end{enumerate}

\fi
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%



\subsection{Metric Spaces}

The concept of a distance is formalized in mathematics through a metric space.
A metric space is a pair \(\parens{M, d}\) where \(M\) is a set
and \(\type{d}{M \times M}{\R}\) is known as the metric, or distance,
function that aims to assign a distance between any two members of \(M\).
A metric space comes equipped with the following axioms
that must hold for any \(x, y, z \in M\):
\begin{enumerate}
  \item[(1)]
    Non-negativity of \(d\): \(d\parens{x, y} \geq 0\).

  \item[(2)]
    Identity of indiscernibles:
    \(d\parens{x, y} = 0\) if and only if \(x = y\).

  \item[(3)]
    Symmetry:
    \(d\parens{x, y} = d\parens{y, x}\).

  \item[(4)]
    Triangle inequality:
    \(d\parens{x, z} \leq d\parens{x, y} + d\parens{y, z}\).

\end{enumerate}


\begin{example}[Euclidean Metric]
  For some \(x_i \in \R^n\),
  let \(x_i\) be the \(i\)th coordinate of the vector.
  Then the Euclidan (L2) metric is defined by
  \begin{align*}
    d\parens{x, y}
      = \sqrt{\sum_{i = 1}^{n} \parens{x_i - y_i}^2}
  \end{align*}
\end{example}


\subsection{Measure Theory}

In mathematical analysis, measure theory is concerned with
the rigorous formulation of ``size''.
Such notions of size have application in generalizations of
familiar concepts such as length, area, and volume,
as well as integration theory.
Informally, for a set \(X\),
the goal of measure theory is to assign a measure (size) to subsets of \(X\).
Often \(X\) is taken to be a space like \(\R^n\),
and common examples of subsets include intervals, rectangles, or boxes.


Formally, a measureable space is a pair
\(\parens{X, \mcal{E}}\) where
\(X\) is a set and \(\mcal{E} \subseteq \powset{X}\) is called
a \(\sigma\)-algebra on \(X\) that satisfies the following properties:
\begin{enumerate}
  \item[(1)]
    Inclusion of empty set and whole space: \(\emptyset, X \in \mcal{E}\).

  \item[(2)]
    Closure under relative complement:
    \(E^c \in \mcal{E}\) if \(E \in \mcal{E}\).

  \item[(3)]
    Closure under countable unions:
    \(E_1, E_2, \ldots \in \mcal{E}\) implies that
    \begin{align*}
      \bigcup_{i = 1}^{\infty} E_i \in \mcal{E}
    \end{align*}

\end{enumerate}

The \(\sigma\)-algebra defined on \(X\) need not be unique.
For instance, the smallest \(\sigma\)-algebra for any set \(X\)
is \(\braces{\emptyset, X}\),
while the largest \(\sigma\)-algebra is the power set \(\powset{X}\).

If \(E\) belongs to the \(\sigma\)-algebra,
that is, \(E \in \mcal{E}\), we say that \(E\) is measruable.
Otherwise for some \(F \in \powset{X} \setminus \mcal{E}\)
we say that \(F\) is un-measurable.

A measureable space can be extended into a measure space by equipping a
measure \(\type{\mu}{\mcal{E}}{\R}\) to form a triple
\(\parens{X, \mcal{E}, \mu}\).
A measure satisfies the following properties:
\begin{enumerate}
  \item[(1)]
    Empty set has trivial measure: \(\mu\parens{\emptyset} = 0\).

  \item[(2)]
    Countable additivity:
    if \(E_1, E_2, \ldots \in \mcal{E}\) are pairwise disjoint, then
    \begin{align*}
      \mu\parens{\bigcup_{i = 1}^{\infty} E_i}
        = \sum_{i = 1}^{\infty} \mu\parens{E_i}
    \end{align*}

\end{enumerate}


\begin{example}[Lebesgue Measure]
  Consider the real line \(\R\)
  and some interval open \(\parens{a, b} \subseteq \R\) with \(a < b\).
  Intuitively one may want to assign the interval a size of
  equal to its length.
  In other words, the measure of \(\parens{a, b}\) should be \(b - a\).

  The idea of using lengths (also, area, volume, etc) as a way to measure
  the size of a set in \(\R^n\) gives rise to the Lebesgue measure
  \(\lambda\).
  But to formally define the Lebesgue measure, we must first
  define the Lebesgue outer measure
  \(\type{\lambda^\star}{\powset{\R}}{\R}\) as follows:
  
  In order to define the Lebesgue mesure \(\lambda\),
  we first define the Lebesgue outer measure \(\lambda^\star\):
  \begin{align*}
    \lambda^\star \parens{E}
      = \inf\braces{\sum_{i = 1}^{\infty} I_i \st
                      \braces{\parens{I_i}}
                      \ \text{is a sequence of open intervals such that} \ 
                      E \subseteq \bigcup_{i = 1}^{\infty} {I_i}}
  \end{align*}

  The difference between an outer measure and a measure is that
  an outer measure is defined on the largest \(\sigma\)-algebra,
  in this case \(\powset{\R}\),
  while a measure tends to be defined on a restricted subset.

  The Lebesgue \(\sigma\)-algebra is a subset of \(\powset{\R}\) that
  is defined as the collection of all sets \(E\) such that
  for any \(A \subseteq \R\) the following property holds with respect
  to the Lebesgue outer-measure \(\lambda^\star\):
  \begin{align*}
    \lambda^\star \parens{E}
      = \lambda^\star \parens{A \cap E} + \lambda^\star \parens{A \cap E^c}
  \end{align*}
  This is called the Carath{\'e}odory criterion,
  and on such sets we set \(\lambda\parens{E} = \lambda^\star \parens{E}\).
  The proof that the Lebesgue measure is indeed a measure can be found
  in texts on real analysis and measure theory.

\end{example}



\begin{example}[Counting Measure]
  Given a set \(X\),
  the counting measure is defined on \(\powset{X}\),
  and just counts the cardinality of each \(E \subseteq X\).
  The counting measure tends to see application in settings
  dealing with finite sets.
\end{example}

\begin{example}[Probability Measure]
  Probability measures are measures
  defined on the probability measure space
  \(\parens{X, \Omega, \mu}\),
  where for the whole space \(\mu\parens{X} = 1\).
\end{example}



\subsection{Mesure Induced Metric}

For a measure space \(\parens{X, \mcal{E}, \mu}\),
an interesting consequence is that a
metric space can be defined on \(\mcal{E}\)
as follows:
\begin{align*}
  d\parens{A, B} = \mu\parens{A \triangle B}
\end{align*}
Where \(\triangle\) is the symmetric set difference.
We now set out to show this.


\begin{lemma}
  \(\parens{A \triangle C}
          \subseteq \parens{A \triangle B} \cup \parens{B \triangle C}\).
\end{lemma}
\begin{proof}
  Observe that we may rewrite the above as follows:
  \begin{align*}
    \parens{A \setminus C} \cup \parens{C \setminus A}
      \subseteq
        \brackets{\parens{A \setminus B} \cup \parens{B \setminus C}} \cup
        \brackets{\parens{B \setminus A} \cup \parens{C \setminus B}}
  \end{align*}
  It then suffices to show that:
  \begin{align*}
    A \setminus C
      \subseteq \parens{A \setminus B} \cup \parens{B \setminus C}
    \qquad
    \qquad
    C \setminus A
      \subseteq \parens{B \setminus A} \cup \parens{C \setminus B}
  \end{align*}
  We take turns examining these.

      If \(x \in A \setminus C\), then this implies that \(x \in A\)
      and \(x \not\in C\).
      There are now two cases, where \(x \in B\) or \(x \not\in B\).
      First assume that \(x \in B\), which will imply that
      \(x \in B \setminus C\).
      Now assume that \(x \not\in B\), which will imply that
      \(x \in A \setminus B\).
      Either way, the implication is that
      \(x \in \parens{A \setminus B} \cup \parens{B \setminus C}\),
      and so it follows that
      \(A \setminus C
      \subseteq \parens{A \setminus B} \cup \parens{B \setminus C}\).

      If \(x \in C \setminus A\), then this implies that
      \(x \in C\) and \(x \not\in A\).
      The argument is similar to the above, in which either
      \(x \in B\) or \(x \not\in B\).
      If \(x \in B\), then \(x \in B \setminus A\),
      and otherwise if \(x \not\in B\) implies that
      \(x \in C \setminus B\).
      Collectively, the two imply that
      \(C \setminus A \subseteq
        \parens{B \setminus A} \cup \parens{C \setminus B}\).

  Collectively, this shows that
  \(\parens{A \triangle C}
          \subseteq \parens{A \triangle B} \cup \parens{B \triangle C}\).
\end{proof}


\begin{theorem}
  If \(\parens{X, \mcal{E}, \mu}\) is a measure space,
  then for \(\type{d}{\mcal{E} \times \mcal{E}}{\Rz}\) defined as:
  \begin{align*}
    d\parens{A, B} = \mu\parens{A \triangle B}
  \end{align*}
  Is a metric function.
\end{theorem}
\begin{proof}
  We prove the conditions necessary for a metric:
  identity, symmetry, and triangle inequality.

      As \(\mu\) is a measure, then for any \(A \in \mcal{E}\):
      \begin{align*}
        d\parens{A, A}
          = \mu\parens{A \triangle A}
          = \mu\parens{\emptyset} = 0
      \end{align*}

      By the symmetry of symmetric set difference,
      for any \(A, B \in \mcal{E}\):
      \begin{align*}
        d\parens{A, B}
          = \mu\parens{A \triangle B}
          = \mu\parens{B \triangle A}
          = d\parens{B, A}
      \end{align*}

      For any \(A, B, C \in \mcal{E}\),
      we have by convexity as shown in the lemma above:
      \begin{align*}
        A \triangle C \subseteq
          \parens{A \triangle B} \cup \parens{B \triangle C}
      \end{align*}
      Then by sub-additivity of measures:
      \begin{align*}
        d\parens{A, C}
          = \mu\parens{A \triangle C}
          \leq \mu\parens{
                \parens{A \triangle B} \cup \parens{B \triangle C}}
          \leq
          \mu\parens{A \triangle B} + \mu\parens{A \triangle C}
          = d\parens{A, B} + d\parens{B, C}
      \end{align*}
\end{proof}




